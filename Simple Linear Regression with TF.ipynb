{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating fake inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are generating data but normally we receive data in various formats. We preprocess it to .npz files which is numpy file format. We load these .npz files to use as inputs in tensorflow\n",
    ".Tensors are n-dimensional arrays similar to numpy arrays, hence .npz files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "observations = 1000\n",
    "\n",
    "xs = np.random.uniform(low=-10, high=10, size=(observations, 1))\n",
    "zs = np.random.uniform(low=-10, high=10, size=(observations, 1))\n",
    "\n",
    "inputs = np.column_stack((xs,zs)) # Stacking two inputs\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating fake targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "noise = np.random.uniform(-1, 1, (observations, 1))\n",
    "\n",
    "targets = 2*xs - 3*zs + 5 + noise\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving to npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('TF_Intro', inputs=inputs, targets=targets) # label = array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading npz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load('TF_Intro.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining input and output sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-3f328d980a4f>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-3f328d980a4f>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    bias_initializer=tf.random.uniform_initializer(minval=-0.1, maxval=0.1))\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Sequential specifies that we will stack layers sequentially\n",
    "    tf.keras.layers.Dense(output_size,\n",
    "                          # Initalizing weights and biases using uniform initializer\n",
    "                          kernel_initializer=tf.random.uniform_initializer(minval=-0.1, maxval=0.1)), \n",
    "                          bias_initializer=tf.random.uniform_initializer(minval=-0.1, maxval=0.1)) \n",
    "    # Dense takes input provided to the model and calculates dot product of inputs and weights and adds the bias\n",
    "])\n",
    "\n",
    "# Custom optimizer with required learning rate\n",
    "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=0.02)\n",
    "\n",
    "#model.compile(optimizer='SGD', loss='mean_squared_error') # With standard SGD\n",
    "model.compile(optimizer=custom_optimizer, loss='mean_squared_error') # With custom SGD\n",
    "\n",
    "# Using mean_squared_error as it is l2 norm loss scaled by number of observations similar to what we need\n",
    "# We could use custom loss function but its harder and not worth the trouble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(training_data['inputs'], training_data['targets'], epochs=100, verbose=2)\n",
    "# Epochs is number of iterations\n",
    "# Verbose set to 0: silent training, 1: progress bar, 2: one liner per epcoh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the weights and biases for first and only layer in our case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the weights and biases are similar to the generator function(```targets = 2*xs - 3*zs + 5 + noise```) which we used earlier to generate targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using model\n",
    "model.predict_on_batch(training_data['inputs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting targets vs predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.squeeze(model.predict_on_batch(training_data['inputs'])), np.squeeze(training_data['targets']))\n",
    "plt.xlabel('outputs')\n",
    "plt.ylabel('targets')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3_TF_2.0",
   "language": "python",
   "name": "python_3_tf_2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
